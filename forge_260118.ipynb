{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/q5t8-jw4c-6h9/forge_colab_notebook/blob/main/forge_260118.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Mg_r-zQGxn7l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "556c3f84-911a-4302-dca5-e93d82d6f4d0",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ git clone https://github.com/q5t8-jw4c-6h9/stable-diffusion-webui-forge /content/stable-diffusion-webui-forge\n",
            "+ git clone https://github.com/q5t8-jw4c-6h9/stablediffusion_w-e-w.git repositories/stable-diffusion-stability-ai\n",
            "+ git fetch origin 0af2869 --depth=1\n",
            "+ git checkout --detach 0af2869\n",
            "Pinned: extensions-builtin/forge_legacy_preprocessors/requirements.txt\n",
            "Pinned: extensions-builtin/sd_forge_controlnet/requirements.txt\n",
            "OK: Cell1 finished.\n"
          ]
        }
      ],
      "source": [
        "#@title Forge環境セットアップ（/content完結・コミット固定0af2869・OpenCVピン）\n",
        "import os, shutil, glob, subprocess, textwrap\n",
        "\n",
        "def run(cmd: str, check=True):\n",
        "    print(\"+\", cmd)\n",
        "    return subprocess.run(cmd, shell=True, check=check, text=True)\n",
        "\n",
        "# 0) 作業ディレクトリを強制復旧\n",
        "os.makedirs(\"/content\", exist_ok=True)\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "# 1) 旧フォルダを安全に消去（存在しなくてもOK）\n",
        "shutil.rmtree(\"/content/stable-diffusion-webui-forge\", ignore_errors=True)\n",
        "\n",
        "# 2) クローン → 指定コミットに固定（参考コミット：0af2869）\n",
        "run(\"git clone https://github.com/q5t8-jw4c-6h9/stable-diffusion-webui-forge /content/stable-diffusion-webui-forge\")\n",
        "os.chdir(\"/content/stable-diffusion-webui-forge\")\n",
        "\n",
        "# ▼▼▼ 修正：起動時のクローンエラー回避のため先行取得 ▼▼▼\n",
        "os.makedirs(\"repositories\", exist_ok=True)\n",
        "run(\"git clone https://github.com/q5t8-jw4c-6h9/stablediffusion_w-e-w.git repositories/stable-diffusion-stability-ai\", check=False)\n",
        "# ▲▲▲ 修正ここまで ▲▲▲\n",
        "\n",
        "# 浅いcloneでも確実に固定\n",
        "run(\"git fetch origin 0af2869 --depth=1\", check=False)\n",
        "run(\"git checkout --detach 0af2869\", check=False)\n",
        "\n",
        "# 3) 内蔵拡張の opencv を固定（NumPy 2.x 巻き上げ防止）\n",
        "paths = glob.glob(\"extensions-builtin/*/requirements.txt\")\n",
        "if not paths:\n",
        "    paths = glob.glob(\"webui/extensions-builtin/*/requirements.txt\")  # 互換レイアウト\n",
        "\n",
        "for p in paths:\n",
        "    try:\n",
        "        with open(p, \"r\", encoding=\"utf-8\") as f:\n",
        "            s = f.read()\n",
        "        s2 = s.replace(\"opencv-python>=4.8.0\", \"opencv-python==4.11.0.86\")\n",
        "        if s2 != s:\n",
        "            with open(p, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(s2)\n",
        "            print(\"Pinned:\", p)\n",
        "        else:\n",
        "            print(\"Unchanged:\", p)\n",
        "    except FileNotFoundError:\n",
        "        print(\"Skip (not found):\", p)\n",
        "\n",
        "print(\"OK: Cell1 finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "xgPZiGfy59Pu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "366df5f7-159b-4116-e2a0-b0525a05f677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "モデルファイルをコピーしました: waiIllustriousSDXL_v160.safetensors\n",
            "モデルファイルをコピーしました: waiSHUFFLENOOB_vPred04.safetensors\n",
            "ControlNetモデルをコピーしました: CN-anytest4_illustrious2_A.safetensors\n",
            "すべてのファイルのコピーが完了しました。\n",
            "downloaded: vae-ft-mse-840000-ema-pruned.safetensors\n",
            "downloaded: sdxl_vae.safetensors\n"
          ]
        }
      ],
      "source": [
        "#@title googleドライブマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# モデルファイルの保存場所\n",
        "model_source_dir = \"/content/drive/MyDrive/model/\"\n",
        "model_target_dir = \"/content/stable-diffusion-webui-forge/models/Stable-diffusion/\"\n",
        "\n",
        "# LoRAファイルの保存場所\n",
        "lora_source_dir = \"/content/drive/MyDrive/LoRA/\"\n",
        "lora_target_dir = \"/content/stable-diffusion-webui-forge/models/Lora/\"\n",
        "\n",
        "# ControlNetモデルの保存場所\n",
        "controlnet_source_dir = \"/content/drive/MyDrive/CNmodel/\"\n",
        "controlnet_target_dir = \"/content/stable-diffusion-webui-forge/models/ControlNet/\"\n",
        "\n",
        "# 保存先のディレクトリを作成する\n",
        "os.makedirs(model_target_dir, exist_ok=True)\n",
        "os.makedirs(lora_target_dir, exist_ok=True)\n",
        "os.makedirs(controlnet_target_dir, exist_ok=True)\n",
        "\n",
        "# モデルファイルのコピー\n",
        "for filename in os.listdir(model_source_dir):\n",
        "    if filename.endswith(\".safetensors\"):\n",
        "        source_file = os.path.join(model_source_dir, filename)\n",
        "        target_file = os.path.join(model_target_dir, filename)\n",
        "        if not os.path.exists(target_file):  # ファイルが存在しない場合のみコピー\n",
        "            shutil.copyfile(source_file, target_file)\n",
        "            print(f\"モデルファイルをコピーしました: {filename}\")\n",
        "        else:\n",
        "            print(f\"モデルファイルは既に存在します: {filename}\")\n",
        "\n",
        "# LoRAファイルのコピー\n",
        "for filename in os.listdir(lora_source_dir):\n",
        "    if filename.endswith(\".safetensors\"):\n",
        "        source_file = os.path.join(lora_source_dir, filename)\n",
        "        target_file = os.path.join(lora_target_dir, filename)\n",
        "        if not os.path.exists(target_file):  # ファイルが存在しない場合のみコピー\n",
        "            shutil.copyfile(source_file, target_file)\n",
        "            print(f\"LoRAファイルをコピーしました: {filename}\")\n",
        "        else:\n",
        "            print(f\"LoRAファイルは既に存在します: {filename}\")\n",
        "\n",
        "# ControlNetモデルのコピー\n",
        "for filename in os.listdir(controlnet_source_dir):\n",
        "    if filename.endswith(\".safetensors\"):\n",
        "        source_file = os.path.join(controlnet_source_dir, filename)\n",
        "        target_file = os.path.join(controlnet_target_dir, filename)\n",
        "        if not os.path.exists(target_file):  # ファイルが存在しない場合のみコピー\n",
        "            shutil.copyfile(source_file, target_file)\n",
        "            print(f\"ControlNetモデルをコピーしました: {filename}\")\n",
        "        else:\n",
        "            print(f\"ControlNetモデルは既に存在します: {filename}\")\n",
        "\n",
        "print(\"すべてのファイルのコピーが完了しました。\")\n",
        "\n",
        "#@markdown ### vae-ft-mse-840000\n",
        "#@markdown [公式ページ](https://huggingface.co/stabilityai/sd-vae-ft-mse-original)\n",
        "use_vae_ft_mse_840000 = True #@param {type: \"boolean\"}\n",
        "if use_vae_ft_mse_840000:\n",
        "  !wget -q https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors --directory-prefix=/content/stable-diffusion-webui-forge/models/VAE/\n",
        "  !echo \"downloaded: vae-ft-mse-840000-ema-pruned.safetensors\"\n",
        "\n",
        "#@markdown ### kl-f8-anime2\n",
        "#@markdown [公式ページ](https://huggingface.co/hakurei/waifu-diffusion-v1-4)\n",
        "use_klf8_anime2 = False #@param {type: \"boolean\"}\n",
        "if use_klf8_anime2:\n",
        "  !wget -q https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt --directory-prefix=/content/stable-diffusion-webui-forge/models/VAE/\n",
        "  !echo \"downloaded: kl-f8-anime2.ckpt\"\n",
        "\n",
        "#@markdown ### SDXL - VAE (SDXL向け)\n",
        "#@markdown [公式ページ](https://huggingface.co/stabilityai/sdxl-vae)\n",
        "use_sdxl_vae = True #@param {type: \"boolean\"}\n",
        "if use_sdxl_vae:\n",
        "  !wget -q https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors --directory-prefix=/content/stable-diffusion-webui-forge/models/VAE/\n",
        "  !echo \"downloaded: sdxl_vae.safetensors\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "683_1gLxoQ0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa6862a2-976e-4c73-ac80-aa702dc87f28",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$ sed -i 's|http://archive.ubuntu.com/ubuntu|http://azure.archive.ubuntu.com/ubuntu|g' /etc/apt/sources.list\n",
            "$ apt-get update -y -o Acquire::Retries=3 -o Acquire::http::Timeout=30\n",
            "$ apt-get install -y --no-install-recommends python3.10 python3.10-venv python3.10-distutils\n",
            "$ python3.10 -m venv /content/py310\n",
            "$ /content/py310/bin/python -m pip install -U 'pip==24.2' 'wheel==0.43.0' 'setuptools==68.2.2'\n",
            "$ /content/py310/bin/pip install 'numpy<2'\n",
            "$ /content/py310/bin/python --version\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.1.2\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp310-cp310-linux_x86_64.whl (2200.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 GB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.16.2\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.16.2%2Bcu121-cp310-cp310-linux_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m134.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock (from torch==2.1.2)\n",
            "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting typing-extensions (from torch==2.1.2)\n",
            "  Downloading https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting sympy (from torch==2.1.2)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch==2.1.2)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch==2.1.2)\n",
            "  Downloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch==2.1.2)\n",
            "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting triton==2.1.0 (from torch==2.1.2)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m119.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /content/py310/lib/python3.10/site-packages (from torchvision==0.16.2) (1.26.4)\n",
            "Collecting requests (from torchvision==0.16.2)\n",
            "  Downloading https://download.pytorch.org/whl/requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.16.2)\n",
            "  Downloading pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.1.2)\n",
            "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting charset-normalizer<3,>=2 (from requests->torchvision==0.16.2)\n",
            "  Downloading https://download.pytorch.org/whl/charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->torchvision==0.16.2)\n",
            "  Downloading https://download.pytorch.org/whl/idna-3.4-py3-none-any.whl (61 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1 (from requests->torchvision==0.16.2)\n",
            "  Downloading https://download.pytorch.org/whl/urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->torchvision==0.16.2)\n",
            "  Downloading https://download.pytorch.org/whl/certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.1.2)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m121.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
            "Downloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m184.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpmath, urllib3, typing-extensions, sympy, pillow, networkx, MarkupSafe, idna, fsspec, filelock, charset-normalizer, certifi, triton, requests, jinja2, torch, torchvision\n",
            "Successfully installed MarkupSafe-2.1.5 certifi-2022.12.7 charset-normalizer-2.1.1 filelock-3.20.0 fsspec-2025.12.0 idna-3.4 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 pillow-12.0.0 requests-2.28.1 sympy-1.14.0 torch-2.1.2+cu121 torchvision-0.16.2+cu121 triton-2.1.0 typing-extensions-4.15.0 urllib3-1.26.13\n",
            "/content\n",
            "Collecting scipy==1.15.3\n",
            "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /content/py310/lib/python3.10/site-packages (from scipy==1.15.3) (1.26.4)\n",
            "Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m129.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy\n",
            "Successfully installed scipy-1.15.3\n",
            "Collecting filterpy==1.4.5\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /content/py310/lib/python3.10/site-packages (from filterpy==1.4.5) (1.26.4)\n",
            "Requirement already satisfied: scipy in /content/py310/lib/python3.10/site-packages (from filterpy==1.4.5) (1.15.3)\n",
            "Collecting matplotlib (from filterpy==1.4.5)\n",
            "  Downloading matplotlib-3.10.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib->filterpy==1.4.5)\n",
            "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib->filterpy==1.4.5)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib->filterpy==1.4.5)\n",
            "  Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (114 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib->filterpy==1.4.5)\n",
            "  Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting packaging>=20.0 (from matplotlib->filterpy==1.4.5)\n",
            "  Downloading packaging-26.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pillow>=8 in /content/py310/lib/python3.10/site-packages (from matplotlib->filterpy==1.4.5) (12.0.0)\n",
            "Collecting pyparsing>=3 (from matplotlib->filterpy==1.4.5)\n",
            "  Downloading pyparsing-3.3.2-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting python-dateutil>=2.7 (from matplotlib->filterpy==1.4.5)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib->filterpy==1.4.5)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading matplotlib-3.10.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m135.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m139.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-26.0-py3-none-any.whl (74 kB)\n",
            "Downloading pyparsing-3.3.2-py3-none-any.whl (122 kB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: filterpy\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110458 sha256=17613792538f01d6682c8d7f581bbcb73c81152954109820cc71858608130ede\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/0c/ea/218f266af4ad626897562199fbbcba521b8497303200186102\n",
            "Successfully built filterpy\n",
            "Installing collected packages: six, pyparsing, packaging, kiwisolver, fonttools, cycler, contourpy, python-dateutil, matplotlib, filterpy\n",
            "Successfully installed contourpy-1.3.2 cycler-0.12.1 filterpy-1.4.5 fonttools-4.61.1 kiwisolver-1.4.9 matplotlib-3.10.8 packaging-26.0 pyparsing-3.3.2 python-dateutil-2.9.0.post0 six-1.17.0\n",
            "Collecting scikit-image==0.19.3\n",
            "  Downloading scikit_image-0.19.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
            "Collecting imageio==2.31.1\n",
            "  Downloading imageio-2.31.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting tifffile==2023.7.10\n",
            "  Downloading tifffile-2023.7.10-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting opencv-python==4.11.0.86\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /content/py310/lib/python3.10/site-packages (from scikit-image==0.19.3) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /content/py310/lib/python3.10/site-packages (from scikit-image==0.19.3) (1.15.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /content/py310/lib/python3.10/site-packages (from scikit-image==0.19.3) (3.4.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /content/py310/lib/python3.10/site-packages (from scikit-image==0.19.3) (12.0.0)\n",
            "Collecting PyWavelets>=1.1.1 (from scikit-image==0.19.3)\n",
            "  Downloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /content/py310/lib/python3.10/site-packages (from scikit-image==0.19.3) (26.0)\n",
            "Downloading scikit_image-0.19.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imageio-2.31.1-py3-none-any.whl (313 kB)\n",
            "Downloading tifffile-2023.7.10-py3-none-any.whl (220 kB)\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m141.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m118.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tifffile, PyWavelets, opencv-python, imageio, scikit-image\n",
            "Successfully installed PyWavelets-1.8.0 imageio-2.31.1 opencv-python-4.11.0.86 scikit-image-0.19.3 tifffile-2023.7.10\n",
            "Collecting PyYAML\n",
            "  Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
            "Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.3/770.3 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyYAML\n",
            "Successfully installed PyYAML-6.0.3\n",
            "Collecting omegaconf==2.3.0\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "Installing collected packages: omegaconf\n",
            "Successfully installed omegaconf-2.3.0\n",
            "Collecting antlr4-python3-runtime==4.9.3\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=c5ca2e0b9f5e4d9681579befd1fd3a29bc2c055eccbdca1b1d4c45b2ef12c29e\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime\n",
            "Successfully installed antlr4-python3-runtime-4.9.3\n",
            "Collecting git+https://github.com/xinntao/BasicSR@v1.4.2\n",
            "  Cloning https://github.com/xinntao/BasicSR (to revision v1.4.2) to /tmp/pip-req-build-rlcpku5a\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/xinntao/BasicSR /tmp/pip-req-build-rlcpku5a\n",
            "  Running command git checkout -q 651835a1b9d38dbbdaf45750f56906be2364f01a\n",
            "  Resolved https://github.com/xinntao/BasicSR to commit 651835a1b9d38dbbdaf45750f56906be2364f01a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: basicsr\n",
            "  Building wheel for basicsr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for basicsr: filename=basicsr-1.4.2-py3-none-any.whl size=214818 sha256=b8162e07f9e3f65c4c7fb420383b12722ea5b3de0f463687cbe6723053fd45da\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1qzgi1hp/wheels/d8/5b/fc/1d7a4dbc5828272f73dbf819fae24940adeb18a87e0506b049\n",
            "Successfully built basicsr\n",
            "Installing collected packages: basicsr\n",
            "Successfully installed basicsr-1.4.2\n",
            "Requirement already satisfied: numpy<2 in /content/py310/lib/python3.10/site-packages (1.26.4)\n",
            "omegaconf 2.3.0\n",
            "antlr4 4.9.3\n",
            "basicsr 1.4.2\n",
            "numpy 1.26.4\n",
            "/content\n",
            "Requirement already satisfied: numpy<2 in /content/py310/lib/python3.10/site-packages (1.26.4)\n",
            "fatal: No names found, cannot describe anything.\n",
            "Python 3.10.12 (main, Jan  8 2026, 06:52:19) [GCC 11.4.0]\n",
            "Version: f0.0.17v1.8.0rc-1.7.0\n",
            "Commit hash: 0af28699c45c1c5bf9cb6818caac6ce881123131\n",
            "Installing clip\n",
            "Installing open_clip\n",
            "Cloning assets into /content/stable-diffusion-webui-forge/repositories/stable-diffusion-webui-assets...\n",
            "Cloning into '/content/stable-diffusion-webui-forge/repositories/stable-diffusion-webui-assets'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 20 (delta 0), reused 20 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (20/20), 132.70 KiB | 1.11 MiB/s, done.\n",
            "Cloning Stable Diffusion into /content/stable-diffusion-webui-forge/repositories/stable-diffusion-stability-ai...\n",
            "Cloning into '/content/stable-diffusion-webui-forge/repositories/stable-diffusion-stability-ai'...\n",
            "remote: Enumerating objects: 564, done.\u001b[K\n",
            "remote: Total 564 (delta 0), reused 0 (delta 0), pack-reused 564 (from 2)\u001b[K\n",
            "Receiving objects: 100% (564/564), 73.43 MiB | 28.53 MiB/s, done.\n",
            "Resolving deltas: 100% (274/274), done.\n",
            "Cloning Stable Diffusion XL into /content/stable-diffusion-webui-forge/repositories/generative-models...\n",
            "Cloning into '/content/stable-diffusion-webui-forge/repositories/generative-models'...\n",
            "remote: Enumerating objects: 1154, done.\u001b[K\n",
            "remote: Counting objects: 100% (516/516), done.\u001b[K\n",
            "remote: Compressing objects: 100% (155/155), done.\u001b[K\n",
            "remote: Total 1154 (delta 408), reused 361 (delta 361), pack-reused 638 (from 5)\u001b[K\n",
            "Receiving objects: 100% (1154/1154), 86.69 MiB | 36.32 MiB/s, done.\n",
            "Resolving deltas: 100% (596/596), done.\n",
            "Cloning K-diffusion into /content/stable-diffusion-webui-forge/repositories/k-diffusion...\n",
            "Cloning into '/content/stable-diffusion-webui-forge/repositories/k-diffusion'...\n",
            "remote: Enumerating objects: 1350, done.\u001b[K\n",
            "remote: Counting objects: 100% (651/651), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 1350 (delta 608), reused 566 (delta 564), pack-reused 699 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1350/1350), 239.59 KiB | 1.92 MiB/s, done.\n",
            "Resolving deltas: 100% (948/948), done.\n",
            "Cloning BLIP into /content/stable-diffusion-webui-forge/repositories/BLIP...\n",
            "Cloning into '/content/stable-diffusion-webui-forge/repositories/BLIP'...\n",
            "remote: Enumerating objects: 277, done.\u001b[K\n",
            "remote: Counting objects: 100% (189/189), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 277 (delta 149), reused 140 (delta 140), pack-reused 88 (from 1)\u001b[K\n",
            "Receiving objects: 100% (277/277), 7.04 MiB | 14.13 MiB/s, done.\n",
            "Resolving deltas: 100% (152/152), done.\n",
            "Installing requirements\n",
            "Installing forge_legacy_preprocessor requirement: fvcore\n",
            "Couldn't install forge_legacy_preprocessor requirement: fvcore.\n",
            "Command: \"/content/py310/bin/python\" -m pip install fvcore --prefer-binary\n",
            "Error code: 1\n",
            "stderr: ERROR: Could not find a version that satisfies the requirement fvcore (from versions: none)\n",
            "ERROR: No matching distribution found for fvcore\n",
            "\n",
            "Warning: Failed to install fvcore, some preprocessors may not work.\n",
            "Installing forge_legacy_preprocessor requirement: mediapipe\n",
            "Installing forge_legacy_preprocessor requirement: onnxruntime\n",
            "Installing forge_legacy_preprocessor requirement: svglib\n",
            "Couldn't install forge_legacy_preprocessor requirement: svglib.\n",
            "Command: \"/content/py310/bin/python\" -m pip install svglib --prefer-binary\n",
            "Error code: 1\n",
            "stdout: Collecting svglib\n",
            "  Downloading svglib-1.6.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting cssselect2>=0.2.0 (from svglib)\n",
            "  Downloading cssselect2-0.8.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting lxml>=6.0.0 (from svglib)\n",
            "  Downloading lxml-6.0.2-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting reportlab>=4.4.3 (from svglib)\n",
            "  Downloading reportlab-4.4.9-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting rlpycairo>=0.4.0 (from svglib)\n",
            "  Downloading rlpycairo-0.4.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tinycss2>=0.6.0 (from svglib)\n",
            "  Downloading tinycss2-1.5.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting webencodings (from cssselect2>=0.2.0->svglib)\n",
            "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /content/py310/lib/python3.10/site-packages (from reportlab>=4.4.3->svglib) (9.5.0)\n",
            "Requirement already satisfied: charset-normalizer in /content/py310/lib/python3.10/site-packages (from reportlab>=4.4.3->svglib) (2.1.1)\n",
            "INFO: pip is looking at multiple versions of rlpycairo to determine which version is compatible with other requirements. This could take a while.\n",
            "\n",
            "stderr: ERROR: Could not find a version that satisfies the requirement pycairo>=1.20.0 (from rlpycairo) (from versions: none)\n",
            "ERROR: No matching distribution found for pycairo>=1.20.0\n",
            "\n",
            "Warning: Failed to install svglib, some preprocessors may not work.\n",
            "Legacy Preprocessor init warning: Unable to install insightface automatically. Please try run `pip install insightface` manually.\n",
            "Installing forge_legacy_preprocessor requirement: handrefinerportable\n",
            "Installing forge_legacy_preprocessor requirement: depth_anything\n",
            "Installing sd-forge-controlnet requirement: fvcore\n",
            "Couldn't install sd-forge-controlnet requirement: fvcore.\n",
            "Command: \"/content/py310/bin/python\" -m pip install fvcore --prefer-binary\n",
            "Error code: 1\n",
            "stderr: ERROR: Could not find a version that satisfies the requirement fvcore (from versions: none)\n",
            "ERROR: No matching distribution found for fvcore\n",
            "\n",
            "Warning: Failed to install fvcore, some preprocessors may not work.\n",
            "Installing sd-forge-controlnet requirement: svglib\n",
            "Couldn't install sd-forge-controlnet requirement: svglib.\n",
            "Command: \"/content/py310/bin/python\" -m pip install svglib --prefer-binary\n",
            "Error code: 1\n",
            "stdout: Collecting svglib\n",
            "  Using cached svglib-1.6.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting cssselect2>=0.2.0 (from svglib)\n",
            "  Using cached cssselect2-0.8.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: lxml>=6.0.0 in /content/py310/lib/python3.10/site-packages (from svglib) (6.0.2)\n",
            "Collecting reportlab>=4.4.3 (from svglib)\n",
            "  Using cached reportlab-4.4.9-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting rlpycairo>=0.4.0 (from svglib)\n",
            "  Using cached rlpycairo-0.4.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tinycss2>=0.6.0 (from svglib)\n",
            "  Using cached tinycss2-1.5.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting webencodings (from cssselect2>=0.2.0->svglib)\n",
            "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /content/py310/lib/python3.10/site-packages (from reportlab>=4.4.3->svglib) (9.5.0)\n",
            "Requirement already satisfied: charset-normalizer in /content/py310/lib/python3.10/site-packages (from reportlab>=4.4.3->svglib) (2.1.1)\n",
            "INFO: pip is looking at multiple versions of rlpycairo to determine which version is compatible with other requirements. This could take a while.\n",
            "\n",
            "stderr: ERROR: Could not find a version that satisfies the requirement pycairo>=1.20.0 (from rlpycairo) (from versions: none)\n",
            "ERROR: No matching distribution found for pycairo>=1.20.0\n",
            "\n",
            "Warning: Failed to install svglib, some preprocessors may not work.\n",
            "Launching Web UI with arguments: --skip-python-version-check --share --enable-insecure-extension-access --opt-sdp-attention --no-hashing\n",
            "Total VRAM 22693 MB, total RAM 54229 MB\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 NVIDIA L4 : native\n",
            "VAE dtype: torch.bfloat16\n",
            "CUDA Stream Activated:  False\n",
            "/content/py310/lib/python3.10/site-packages/timm/models/layers/__init__.py:49: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "Using pytorch cross attention\n",
            "*** Error loading script: preprocessor_marigold.py\n",
            "    Traceback (most recent call last):\n",
            "      File \"/content/stable-diffusion-webui-forge/modules/scripts.py\", line 544, in load_scripts\n",
            "        script_module = script_loading.load_module(scriptfile.path)\n",
            "      File \"/content/stable-diffusion-webui-forge/modules/script_loading.py\", line 10, in load_module\n",
            "        module_spec.loader.exec_module(module)\n",
            "      File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
            "      File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "      File \"/content/stable-diffusion-webui-forge/extensions-builtin/forge_preprocessor_marigold/scripts/preprocessor_marigold.py\", line 10, in <module>\n",
            "        from marigold.model.marigold_pipeline import MarigoldPipeline\n",
            "      File \"/content/stable-diffusion-webui-forge/extensions-builtin/forge_preprocessor_marigold/marigold/model/marigold_pipeline.py\", line 9, in <module>\n",
            "        from diffusers import (\n",
            "      File \"/content/py310/lib/python3.10/site-packages/diffusers/__init__.py\", line 5, in <module>\n",
            "        from .utils import (\n",
            "      File \"/content/py310/lib/python3.10/site-packages/diffusers/utils/__init__.py\", line 37, in <module>\n",
            "        from .dynamic_modules_utils import get_class_from_dynamic_module\n",
            "      File \"/content/py310/lib/python3.10/site-packages/diffusers/utils/dynamic_modules_utils.py\", line 28, in <module>\n",
            "        from huggingface_hub import cached_download, hf_hub_download, model_info\n",
            "    ImportError: cannot import name 'cached_download' from 'huggingface_hub' (/content/py310/lib/python3.10/site-packages/huggingface_hub/__init__.py)\n",
            "\n",
            "---\n",
            "ControlNet preprocessor location: /content/stable-diffusion-webui-forge/models/ControlNetPreprocessor\n",
            "Loading weights [None] from /content/stable-diffusion-webui-forge/models/Stable-diffusion/waiIllustriousSDXL_v160.safetensors\n",
            "2026-01-23 22:43:13,728 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet UI callback registered.\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://aaac72cd5984aa1300.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Startup time: 101.5s (prepare environment: 89.4s, import torch: 3.7s, import gradio: 0.9s, setup paths: 0.6s, initialize shared: 0.1s, other imports: 0.8s, load scripts: 2.0s, create ui: 1.4s, gradio launch: 2.5s).\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.text_projection', 'cond_stage_model.clip_g.transformer.text_model.embeddings.position_ids', 'cond_stage_model.clip_l.logit_scale'}\n",
            "To load target model SDXLClipModel\n",
            "Begin to load 1 model\n",
            "[Memory Management] Current Free GPU Memory (MB) =  22503.37109375\n",
            "[Memory Management] Model Memory (MB) =  2144.3546981811523\n",
            "[Memory Management] Minimal Inference Memory (MB) =  1024.0\n",
            "[Memory Management] Estimated Remaining GPU Memory (MB) =  19335.016395568848\n",
            "Moving model(s) has taken 0.48 seconds\n",
            "Model loaded in 35.4s (load weights from disk: 4.2s, forge load real models: 30.5s, calculate empty prompt: 0.7s).\n",
            "X/Y/Z plot will create 12 images on 1 2x3 grid; 2 images per cell. (Total steps to process: 720)\n",
            "\n",
            "Total progress: 0it [00:00, ?it/s]\u001b[ADownloading VAEApprox model to: /content/stable-diffusion-webui-forge/models/VAE-approx/vaeapprox-sdxl.pt\n",
            "100% 209k/209k [00:00<00:00, 9.42MB/s]\n",
            "To load target model SDXL\n",
            "Begin to load 1 model\n",
            "[Memory Management] Current Free GPU Memory (MB) =  20685.07666015625\n",
            "[Memory Management] Model Memory (MB) =  4897.086494445801\n",
            "[Memory Management] Minimal Inference Memory (MB) =  1024.0\n",
            "[Memory Management] Estimated Remaining GPU Memory (MB) =  14763.99016571045\n",
            "Moving model(s) has taken 1.32 seconds\n",
            "  0% 0/30 [00:00<?, ?it/s]\n",
            "  3% 1/30 [00:00<00:20,  1.39it/s]\n",
            "  7% 2/30 [00:01<00:17,  1.62it/s]\n",
            " 10% 3/30 [00:01<00:15,  1.73it/s]\n",
            " 13% 4/30 [00:02<00:14,  1.77it/s]\n",
            " 17% 5/30 [00:02<00:13,  1.80it/s]\n",
            " 20% 6/30 [00:03<00:13,  1.81it/s]\n",
            " 23% 7/30 [00:03<00:12,  1.83it/s]\n",
            " 27% 8/30 [00:04<00:12,  1.83it/s]\n",
            " 30% 9/30 [00:05<00:11,  1.84it/s]\n",
            " 33% 10/30 [00:05<00:10,  1.84it/s]\n",
            " 37% 11/30 [00:06<00:10,  1.84it/s]\n",
            " 40% 12/30 [00:06<00:09,  1.84it/s]\n",
            " 43% 13/30 [00:07<00:09,  1.83it/s]\n",
            " 47% 14/30 [00:07<00:08,  1.82it/s]\n",
            " 50% 15/30 [00:08<00:08,  1.82it/s]\n",
            " 53% 16/30 [00:08<00:07,  1.81it/s]\n",
            " 57% 17/30 [00:09<00:07,  1.81it/s]\n",
            " 60% 18/30 [00:10<00:06,  1.80it/s]\n",
            " 63% 19/30 [00:10<00:06,  1.80it/s]\n",
            " 67% 20/30 [00:11<00:05,  1.80it/s]\n",
            " 70% 21/30 [00:11<00:05,  1.79it/s]\n",
            " 73% 22/30 [00:12<00:04,  1.79it/s]\n",
            " 77% 23/30 [00:12<00:03,  1.79it/s]\n",
            " 80% 24/30 [00:13<00:03,  1.79it/s]\n",
            " 83% 25/30 [00:13<00:02,  1.79it/s]\n",
            " 87% 26/30 [00:14<00:02,  1.79it/s]\n",
            " 90% 27/30 [00:15<00:01,  1.78it/s]\n",
            " 93% 28/30 [00:15<00:01,  1.78it/s]\n",
            " 97% 29/30 [00:16<00:00,  1.78it/s]\n",
            "100% 30/30 [00:16<00:00,  1.79it/s]\n",
            "  0% 0/30 [00:00<?, ?it/s]\n",
            "  3% 1/30 [00:00<00:15,  1.84it/s]\n",
            "  7% 2/30 [00:01<00:15,  1.79it/s]\n",
            " 10% 3/30 [00:01<00:15,  1.78it/s]\n",
            " 13% 4/30 [00:02<00:14,  1.78it/s]\n",
            " 17% 5/30 [00:02<00:14,  1.77it/s]\n",
            " 20% 6/30 [00:03<00:13,  1.77it/s]\n",
            " 23% 7/30 [00:03<00:13,  1.77it/s]\n",
            " 27% 8/30 [00:04<00:12,  1.77it/s]\n",
            " 30% 9/30 [00:05<00:11,  1.77it/s]\n",
            " 33% 10/30 [00:05<00:11,  1.76it/s]\n",
            " 37% 11/30 [00:06<00:10,  1.76it/s]\n",
            " 40% 12/30 [00:06<00:10,  1.76it/s]\n",
            " 43% 13/30 [00:07<00:09,  1.76it/s]\n",
            " 47% 14/30 [00:07<00:09,  1.76it/s]\n",
            " 50% 15/30 [00:08<00:08,  1.75it/s]\n",
            " 53% 16/30 [00:09<00:07,  1.75it/s]\n",
            " 57% 17/30 [00:09<00:07,  1.75it/s]\n",
            " 60% 18/30 [00:10<00:06,  1.75it/s]\n",
            " 63% 19/30 [00:10<00:06,  1.75it/s]\n",
            " 67% 20/30 [00:11<00:05,  1.75it/s]\n",
            " 70% 21/30 [00:11<00:05,  1.74it/s]\n",
            " 73% 22/30 [00:12<00:04,  1.74it/s]\n",
            " 77% 23/30 [00:13<00:04,  1.74it/s]\n",
            " 80% 24/30 [00:13<00:03,  1.74it/s]\n",
            " 83% 25/30 [00:14<00:02,  1.73it/s]\n",
            " 87% 26/30 [00:14<00:02,  1.73it/s]\n",
            " 90% 27/30 [00:15<00:01,  1.73it/s]\n",
            " 93% 28/30 [00:15<00:01,  1.73it/s]\n",
            " 97% 29/30 [00:16<00:00,  1.73it/s]\n",
            "100% 30/30 [00:17<00:00,  1.75it/s]\n",
            "To load target model AutoencoderKL\n",
            "Begin to load 1 model\n",
            "[Memory Management] Current Free GPU Memory (MB) =  15662.6396484375\n",
            "[Memory Management] Model Memory (MB) =  159.55708122253418\n",
            "[Memory Management] Minimal Inference Memory (MB) =  1024.0\n",
            "[Memory Management] Estimated Remaining GPU Memory (MB) =  14479.082567214966\n",
            "Moving model(s) has taken 0.06 seconds\n",
            "  0% 0/30 [00:00<?, ?it/s]\n",
            "  3% 1/30 [00:00<00:15,  1.82it/s]\n",
            "  7% 2/30 [00:01<00:15,  1.75it/s]\n",
            " 10% 3/30 [00:01<00:15,  1.75it/s]\n",
            " 13% 4/30 [00:02<00:15,  1.73it/s]\n",
            " 17% 5/30 [00:02<00:14,  1.73it/s]\n",
            " 20% 6/30 [00:03<00:13,  1.72it/s]\n",
            " 23% 7/30 [00:04<00:13,  1.72it/s]\n",
            " 27% 8/30 [00:04<00:12,  1.72it/s]"
          ]
        }
      ],
      "source": [
        "#@title forgeの起動\n",
        "#セル3Forge起動準備（Python 3.10 venv構築）（/content完結）\n",
        "import os, subprocess\n",
        "\n",
        "def run(cmd, check=True):\n",
        "    print(\"$\", cmd)\n",
        "    return subprocess.run(cmd, shell=True, check=check)\n",
        "\n",
        "# 既存の venv が 3.10 系で正常ならスキップ\n",
        "if os.path.exists(\"/content/py310/bin/python\"):\n",
        "    out = subprocess.run(\"/content/py310/bin/python -V\", shell=True, capture_output=True, text=True)\n",
        "    if out.returncode == 0 and out.stdout.startswith(\"Python 3.10.\"):\n",
        "        print(\"[skip] 既存の /content/py310 は Python 3.10 系。再作成をスキップします。\")\n",
        "    else:\n",
        "        run(\"rm -rf /content/py310\")\n",
        "\n",
        "if not os.path.exists(\"/content/py310/bin/python\"):\n",
        "    # 1) APT ミラー対策\n",
        "    run(\"sed -i 's|http://archive.ubuntu.com/ubuntu|http://azure.archive.ubuntu.com/ubuntu|g' /etc/apt/sources.list\", check=False)\n",
        "    run(\"apt-get update -y -o Acquire::Retries=3 -o Acquire::http::Timeout=30\", check=False)\n",
        "    # 2) Python 3.10 導入\n",
        "    if run(\"apt-get install -y --no-install-recommends python3.10 python3.10-venv python3.10-distutils\", check=False).returncode != 0:\n",
        "        run(\"apt-get install -y --no-install-recommends python3.10 python3.10-venv python3-distutils\", check=False)\n",
        "    # 3) venv 作成\n",
        "    run(\"python3.10 -m venv /content/py310\", check=False)\n",
        "    # 4) pip ブートストラップ\n",
        "    if not os.path.exists(\"/content/py310/bin/pip\"):\n",
        "        run(\"python3.10 -m ensurepip --upgrade\", check=False)\n",
        "        if not os.path.exists(\"/content/py310/bin/python\"):\n",
        "            run(\"rm -rf /content/py310\", check=False)\n",
        "            run(\"python3.10 -m venv /content/py310\", check=False)\n",
        "        if not os.path.exists(\"/content/py310/bin/pip\"):\n",
        "            run(\"curl -sS https://bootstrap.pypa.io/get-pip.py -o /tmp/get-pip.py\", check=True)\n",
        "            run(\"/content/py310/bin/python /tmp/get-pip.py\", check=True)\n",
        "\n",
        "# 安定版に固定\n",
        "run(\"/content/py310/bin/python -m pip install -U 'pip==24.2' 'wheel==0.43.0' 'setuptools==68.2.2'\")\n",
        "run(\"/content/py310/bin/pip install 'numpy<2'\")\n",
        "run(\"/content/py310/bin/python --version\")\n",
        "\n",
        "#セル4 PyTorch 2.1.2 + cu121 インストール\n",
        "#/content 側の venv にインストール\n",
        "!/content/py310/bin/pip install \\\n",
        "  torch==2.1.2 torchvision==0.16.2 --index-url https://download.pytorch.org/whl/cu121\n",
        "# xFormers は任意。torch==2.1.2 と相性が良いのは 0.0.23 系。\n",
        "# !/content/py310/bin/pip install xformers==0.0.23.post1 --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "#セル5 起動前クリア（venv削除）\n",
        "# ▼修正: code1.txtに合わせてパスを /content/stable-diffusion-webui-forge に統一\n",
        "%cd /content/stable-diffusion-webui-forge\n",
        "# 以前の（Python 3.12系などの）venv は競合するので削除\n",
        "!rm -rf venv\n",
        "\n",
        "#セル6 requirements_versions 調整\n",
        "# 念のためバックアップ（存在時のみ）\n",
        "!bash -lc 'test -f requirements_versions.txt && cp -n requirements_versions.txt requirements_versions.bak || true'\n",
        "# jsonmerge 1.8.0 → 1.9.2（存在時のみ）\n",
        "!bash -lc \"test -f requirements_versions.txt && sed -i 's/jsonmerge==1\\.8\\.0/jsonmerge==1.9\\.2/' requirements_versions.txt || true\"\n",
        "# 競合回避（存在時のみ）\n",
        "!bash -lc \"test -f requirements_versions.txt && sed -i '/^protobuf==/d' requirements_versions.txt || true\"\n",
        "!bash -lc \"test -f requirements_versions.txt && sed -i '/^Pillow==/d' requirements_versions.txt || true\"\n",
        "# basicsr==1.4.2 はPyPIに無いのでコメントアウト\n",
        "!bash -lc \"test -f requirements_versions.txt && sed -i 's/^basicsr==1\\.4\\.2/# basicsr==1.4.2 (installed from GitHub)/' requirements_versions.txt || true\"\n",
        "\n",
        "# セル7 SciPy/FilterPy 先行インストール\n",
        "# ▼修正: 消えていた必須ライブラリ(SciPy/FilterPy)を復元\n",
        "!/content/py310/bin/pip install --only-binary=:all: \"scipy==1.15.3\"\n",
        "!/content/py310/bin/pip install --no-binary=filterpy \"filterpy==1.4.5\"\n",
        "# ▼修正: scikit-imageは0.19.3でOK（1.x系ビルド確保のため）\n",
        "!/content/py310/bin/pip install --only-binary=:all: \\\n",
        "  \"scikit-image==0.19.3\" \\\n",
        "  \"imageio==2.31.1\" \\\n",
        "  \"tifffile==2023.7.10\" \\\n",
        "  \"opencv-python==4.11.0.86\"\n",
        "\n",
        "# セル8\n",
        "# omegaconf のピンをrequirementsから外して明示固定\n",
        "!bash -lc \"test -f requirements_versions.txt && sed -i '/^omegaconf==/d' requirements_versions.txt || true\"\n",
        "# PyYAML不足によるimportエラー修正\n",
        "!/content/py310/bin/pip install \"PyYAML\"\n",
        "!/content/py310/bin/pip install --no-deps \"omegaconf==2.3.0\"\n",
        "# antlr は 4.9.3 を先入れ\n",
        "!/content/py310/bin/pip install --no-binary=:all: \"antlr4-python3-runtime==4.9.3\"\n",
        "# BasicSR を依存なしでインストール\n",
        "!/content/py310/bin/pip install --no-deps \"git+https://github.com/xinntao/BasicSR@v1.4.2\"\n",
        "# 念のため numpy<2 を再ピン\n",
        "!/content/py310/bin/pip install \"numpy<2\"\n",
        "\n",
        "# 確認\n",
        "!/content/py310/bin/python -c \"import omegaconf, importlib.metadata, numpy; \\\n",
        "print('omegaconf', omegaconf.__version__); \\\n",
        "print('antlr4', importlib.metadata.version('antlr4-python3-runtime')); \\\n",
        "print('basicsr', importlib.metadata.version('basicsr')); \\\n",
        "print('numpy', numpy.__version__)\"\n",
        "\n",
        "# ▼▼▼ 追加：モデルフォルダが空ならダミーファイルを生成してDLを阻止 ▼▼▼\n",
        "import os\n",
        "model_dir = \"/content/stable-diffusion-webui-forge/models/Stable-diffusion\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# フォルダ内にモデルファイルがない場合のみ実行\n",
        "if not any(f.endswith(('.safetensors', '.ckpt')) for f in os.listdir(model_dir)):\n",
        "    # 0バイトのダミーファイルを作成\n",
        "    with open(os.path.join(model_dir, \"dummy_skip_download.safetensors\"), \"w\") as f:\n",
        "        f.write(\"dummy\")\n",
        "    print(\"生成AI: デフォルトモデルのダウンロードを回避するため、ダミーファイルを設置しました。\")\n",
        "# ▲▲▲ 追加ここまで ▲▲▲\n",
        "\n",
        "#セル10起動\n",
        "%cd /content/stable-diffusion-webui-forge\n",
        "\n",
        "# 念のため、中途半端に作られたフォルダを再度クリア（安全策）\n",
        "!rm -rf /content/stable-diffusion-webui-forge/repositories/stable-diffusion-stability-ai\n",
        "\n",
        "# ▼▼▼ 追加: NumPy 2.x をあらゆる手段で阻止する「鉄壁の制約ファイル」を作成 ▼▼▼\n",
        "!echo \"numpy<2\" > /content/numpy_constraint.txt\n",
        "# ▲▲▲ 追加ここまで ▲▲▲\n",
        "\n",
        "# NumPy 2.x 対策（念のための事前インストール）\n",
        "!/content/py310/bin/pip install \"numpy<2\"\n",
        "\n",
        "# 起動\n",
        "# ▼修正: PIP_CONSTRAINT 環境変数を追加し、起動中の勝手なアップグレードを禁止\n",
        "!env -u MPLBACKEND \\\n",
        "  PIP_ONLY_BINARY=\":all:\" \\\n",
        "  PIP_NO_BINARY=\"filterpy,antlr4-python3-runtime\" \\\n",
        "  PIP_CONSTRAINT=\"/content/numpy_constraint.txt\" \\\n",
        "  LAUNCH_USE_SYSTEM_PYTHON=1 \\\n",
        "  PYTHON=/content/py310/bin/python \\\n",
        "  MPLBACKEND=Agg \\\n",
        "  STABLE_DIFFUSION_REPO=https://github.com/q5t8-jw4c-6h9/stablediffusion_w-e-w.git \\\n",
        "  /content/py310/bin/python launch.py \\\n",
        "    --skip-python-version-check \\\n",
        "    --share \\\n",
        "    --enable-insecure-extension-access \\\n",
        "    --opt-sdp-attention \\\n",
        "    --no-hashing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "ytOGQhDSNJ1j"
      },
      "outputs": [],
      "source": [
        "#@title ダウンロード(google driveマウントしないと落とせない)\n",
        "# 画像をZIPファイルにまとめる\n",
        "!zip -r /content/output_images.zip /content/stable-diffusion-webui-forge/output\n",
        "\n",
        "# ZIPファイルをGoogle Driveにコピーする\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# 元のZIPファイルのパス\n",
        "source_path = '/content/output_images.zip'\n",
        "\n",
        "# Google Driveの保存先パス\n",
        "drive_path = '/content/drive/MyDrive/output_images.zip'  # 適宜パスを変更してください\n",
        "\n",
        "# ファイルをコピー\n",
        "if os.path.exists(source_path):\n",
        "    shutil.copy(source_path, drive_path)\n",
        "    print(f\"ファイルが正常にGoogle Driveにコピーされました: {drive_path}\")\n",
        "else:\n",
        "    print(f\"エラー: 元のファイル {source_path} が見つかりません。\")\n",
        "\n",
        "# コピーを確認\n",
        "if os.path.exists(drive_path):\n",
        "    print(\"確認: ファイルがGoogle Driveに存在します。\")\n",
        "else:\n",
        "    print(\"警告: ファイルがGoogle Driveに見つかりません。\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "W97ime8hgjVn"
      },
      "outputs": [],
      "source": [
        "#@title google driveマウント　独立　単体\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1RpIgnB_UNEwPzXvbVG5LR32T5_y89WYv",
      "authorship_tag": "ABX9TyOc3bz6hqjeMHSmGBeSt0PX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}